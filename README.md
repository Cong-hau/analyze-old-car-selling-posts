# Context
I am a member of fascinating marketing team, work for the old car dealer company in Ho Chi Minh City, Viet Nam. One day, our executives realized that the Turn Over ratio tends to increase, it means we need more time to sell a old car and Return on Investment tends to descrease, go down, it is a dramactical. By a abnormal meeting, the executives would like to know where is the cause of these problems, so my team decided to research market, research competitors. The understanding of market's insight, can help me a lot.

# Ask phase: clarify the resources available (input), how, what exactly objectives are expected (output).

Input: A enthusiasm body without anything: no data, no relative report. :) 

Output:
1. How is the selling volumn? 
2. What brand of car, car model is sold the most? By time and By area.
3. What old car do have sell ratio the most, the least?

Define How: 
1. Because most of people usually use digital marketing to find who are potential customers, it includes vary digital tools together such as: posting in e-commerce flatforms (Chotot.vn, oto.com.vn) or renting advertising potision (Google-Ad, Facebook-Ad), although there are multiple traditional marketing methods. So we can use selling post volumn on Internet to anwser the second question and make a relationship with selling volumn.
2. Define the sell ratio: total of old car is sold / total of new car is sold which has the same manufacturing year and car model.

What is the data exactly & where do I get them?
1. Selling post infomation: brand, model, kilometers, price, post's district, post's city, posting time, link (as Post's ID) on e-commerce flatforms. Aim to personal project so to simplify I have just scraped data from chotot.vn
2. Sales report from VAMA

# Prepare phase: Get data.
Before scarping, let's make awareness of structure post on Chotot.vn
1. The existed time of each post is 60 dates. So, it can not to get data which older than 60 dates. 
2. All posts have unique link, so use link as post's ID.
3. All posts use a common strutured. In detail: brand, model, kilometers, price, post's district, post's city and link is got by Python, BeautifulSoup module. Posting time is generated by API script, so use Python, Selenium module.

## Scraping code

<details><summary> Get post's link  :arrow_down: </summary>

```python
'''Get all link of posts'''
import requests
from bs4 import BeautifulSoup

posts = []
for i in range(0,1000):
    url = 'https://xe.chotot.com/mua-ban-oto-cu-sdca1?page={}'.format(i)
    response = requests.get(url, timeout=10)
    if response.status_code != 200:
        print('time out')
        continue
    content = response.content
    soup = BeautifulSoup(content, 'html.parser')
    for y in soup.find_all('a', class_="AdItem_adItem__gDDQT"):
        link = 'https://xe.chotot.com'+y['href']
        posts.append(link)
    print(i)
print(len(posts)) #20015
```
</details>

<details><summary> Check unique of link and save post's link :arrow_down: </summary>

```python
#find unique link posts
uni_posts = set(posts) #19897
posts = list(uni_posts)
#save posts list into txt
with open('posts7-2-2023.txt', 'w') as f:
    for s in posts:
        f.write(s+'\n')
```

![image](https://github.com/Cong-hau/analyze-old-car-selling-posts/blob/f770049f7ffefcbbb9ab1f4aca84f5083337fc00/images/link_post.png)

</details>

<details><summary> Get post's infomation :arrow_down: </summary>

```python
'''read list into txt'''
with open("posts7-2-2023.txt", 'r') as f:
    posts = [line.rstrip('\n') for line in f]
print(len(posts))


'''Get data from all posts'''
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import re

data = []
index = 0
for url in posts[0]:
    try:
        response = requests.get(url, timeout=15)
    except requests.Timeout:
        continue
    if response.status_code != 200:
        continue
    content = response.content
    soup = BeautifulSoup(content, 'html.parser')
    #brand
    brand = soup.find('a', itemprop = 'carbrand')
    if brand is not None:
        brand = brand.string
    #carmodel
    carmodel = soup.find('a', itemprop = 'carmodel')
    if carmodel is not None:
        carmodel = carmodel.string
    #Manufactural year
    mfyear_string = soup.find('span', itemprop = 'mfdate')
    if mfyear_string is None:
        mfyear = None
    else:
        mfyear_string = mfyear_string.string
        try:
            mftime = datetime.strptime(mfyear_string, '%Y')
            mfyear = mftime.year
        except ValueError:
            mfyear = mfyear_string
    #km
    km_string = soup.find('span', itemprop = 'mileage_v2')
    if km_string is None:
        km = None
    else:
        km = int(km_string.string)
    #Transmission, Fuel
    gearbox = soup.find('span', itemprop = 'gearbox')
    if gearbox is not None:
        gearbox = gearbox.string
    fuel = soup.find('span', itemprop = 'fuel')
    if fuel is not None:
        fuel = fuel.string
    #Price
    price_string = soup.find('span', itemprop = 'price')
    if price_string is None:
        price = None
    else:
        price_string = price_string.text
        price = int(price_string[0:-3].replace('.','')) #remove '.','Ä‘',' ' and convert to int
    #Area: dictrict, city
    script = soup.find('script', id='__NEXT_DATA__').string

    start_pattern_district = 'area_name":"'
    start_index_district = re.search(start_pattern_district, script)
    end_pattern_district = '","region'
    end_index_district = re.search(end_pattern_district, script)
    if start_index_district is None:
        district = None
    elif end_index_district is None:
        district = None
    else:
        district = script[start_index_district.span()[1]:end_index_district.span()[0]]
    
    start_pattern_city = 'region_name":"'
    start_index_city = re.search(start_pattern_city, script)
    end_pattern_city = '","company_ad'
    end_index_city = re.search(end_pattern_city, script)
    if start_index_city is None:
        city = None
    elif end_index_city is None:
        city = None
    else:
        city = script[start_index_city.span()[1]:end_index_city.span()[0]]
    #Posted time
    start_pattern_time = 'date":"'
    start_index_time = re.search(start_pattern_time, script)
    end_pattern_time = '","access-control-expose-headers"'
    end_index_time = re.search(end_pattern_time, script)
    if start_index_time is None:
        posted_time, posted_year, posted_month = None, None, None
    elif end_index_city is None:
        posted_time, posted_year, posted_month = None, None, None
    else:
        posted_time_string = script[start_index_time.span()[1]:end_index_time.span()[0]]
        try:
            posted_time = datetime.strptime(posted_time_string, '%a, %d %b %Y %H:%M:%S %Z')
            posted_year = posted_time.year
            posted_month = posted_time.strftime('%b')
        except ValueError:
            posted_time, posted_year, posted_month = None, None, None

    #PhoneNumber
    #Href
    href = url
    data.append({'brand': brand,
        'carmodel': carmodel,
        'year': mfyear,
        'km': km,
        'tranmission': gearbox,
        'fuel': fuel,
        'price': price,
        'district': district,
        'city': city,
        'posted_year': posted_year,
        'posted_month': posted_month,
        'link': href
        })
    index += 1
    print(index)
#print(len(data))
#Export: Write data into a new csv
import csv
keys = data[0].keys()   
'''with open('data.csv', 'w', encoding='utf8', newline='') as output_file:
    dict_writer = csv.DictWriter(output_file, keys)
    dict_writer.writeheader()
    dict_writer.writerows(data)'''
#Append new data into existed csv
with open('data.csv', 'a', encoding='utf8', newline='') as output_file:
    dict_writer = csv.DictWriter(output_file, keys)
    dict_writer.writerows(data)
```

![image](https://github.com/Cong-hau/analyze-old-car-selling-posts/blob/f770049f7ffefcbbb9ab1f4aca84f5083337fc00/images/post_info.png)

</details>

<details><summary> Get posting time :arrow_down: </summary>

```python
import selenium
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
import time

link = ['https://xe.chotot.com/mua-ban-oto-quan-8-tp-ho-chi-minh/102698000.htm','https://xe.chotot.com/mua-ban-oto-quan-3-tp-ho-chi-minh/102398170.htm']
driver = webdriver.Chrome()
for url in link:
    driver.get(url)
    time.sleep(5)

    posted_time_ele = driver.find_element(By.XPATH, '//*[@id="__next"]/div/div[3]/div[1]/div/div[4]/div/div[2]/div/div/div/span/div/div[2]/span')
    print(posted_time_ele.text) #30s for 2 posts, so use selenium take a lot of time
```

![image](https://github.com/Cong-hau/analyze-old-car-selling-posts/blob/f770049f7ffefcbbb9ab1f4aca84f5083337fc00/images/posting_time.png)

</details>

Because of getting posting time is low performance. (30 seconds/ 2 posts), so I skipped this data aim to learning objectives

# Process phase: Use python to check null value, check duplicate, check format of data and check wrong data

<details><summary> Get briefly of data set :arrow_down: </summary>

```python
import pandas as pd

'''Load data'''
df = pd.read_csv('data.csv')

'''Get briefly of dataset'''
df.head()
df.info() 
df.describe()
df.columns
```

![image](https://github.com/Cong-hau/analyze-old-car-selling-posts/blob/b127c994cfa195dfb1a9ba852610419fbdc26927/images/df_info.png)

</details>

<details><summary> Clean data:arrow_down: </summary>

```python
'''Cleaning empty value'''
#View the empty value
df[df.isnull().any(axis=1)] 
```

![image](https://github.com/Cong-hau/analyze-old-car-selling-posts/blob/b127c994cfa195dfb1a9ba852610419fbdc26927/images/null_value.png)

```python
km_mode = df['km'].mode() #find mode value and ignore NaN value
km_mode = float(km_mode) #mode() function create object so have to change data type before use on fillna method
df['km'].fillna(km_mode, inplace=True) 

#View again include brand, carmodel so drop the rest of na
df.dropna(inplace=True) 

'''Cleaning wrong format'''
df.info()
convert_dict = {'km':int, 'price':int, 'posted_year':str}
df = df.astype(convert_dict)

'''Check wrong data in city'''
#view unique in city column
set(df['city']) #do not have misspelling and obey the standard

'''Remove duplicates'''
df.duplicated() #All is False >> no duplicates

'''#Save dataset after cleaning'''
df.to_csv('cleaned_data.csv', index=False) #remove index number
```

![image](https://github.com/Cong-hau/analyze-old-car-selling-posts/blob/b127c994cfa195dfb1a9ba852610419fbdc26927/images/check_duplicates.png)

</details>

# Analyze phase: 
<details><summary> Load data :arrow_down: </summary>

```python
import pandas as pd

'''1.Load data'''
df = pd.read_csv('cleaned_data.csv')

'''2.View data'''
df.info()
df.head()
df = df.astype({'posted_year':int})#remove number after digit point of float type
df = df.astype({'posted_year':str})#convert data type in a line
```
</details>

<details><summary> Extract Sell Ratio :arrow_down: </summary>

```python
#Create a new dataframe 
top_posts = df.groupby(['brand','carmodel','year']).size().sort_values(ascending=False)
sell_ratio = top_posts.reset_index() #convert series (groupby result) into dataframe
sell_ratio.rename(columns={0:'num_posts'}, inplace=True) #change column name

#Filter manufacture year (2020,2021,2022)
sell_ratio = sell_ratio[sell_ratio['year'].isin(['2020','2021','2022'])]

#Filter brand which have data revenue in VAMA
filter_brand = ['Toyota','Ford','Honda','Mitsubishi','Kia','Mazda','Suzuki','Isuzu']
sell_ratio = sell_ratio[sell_ratio['brand'].isin(filter_brand)]

#Filter number of posts which quite large to analyze, after view unique value of num_posts, I chose 20
sell_ratio = sell_ratio[sell_ratio['num_posts'] > 20]

#Add data from VAMA statements
vama_data = [30251, 15650, 13291, 5485, 11365, 16447, 16844, 8512, 2793, 12033, 16122, 11803, 9745,
            13616, 19931, 4206, 18411, 6075, 1961, 5902, 7653, 3969, 14696, 5589, 3683, 5916, 1948,
            23529, 21473, 14104, 2478, 6352, 11404, 9812, 21983, 3195, 6526, 9775, 2813, 6065, 5406,
            9320, 4725, 5333, 9578, 5423, 2906, 5175, 867, 4471, 10505, 1076, 12700, 9446, 7214, 10230, 
            5854, 12398, 8334, 1710]

vama_report_2020 = 'http://vama.org.vn/Data/upload/files/2020/Thang12-2020/VAMA%20sales%20report%20December%202020%20-%20Detail.pdf'
vama_report_2021 = 'http://vama.org.vn/Data/upload/files/2021/Thang12-2021/VAMA%20sales%20report%20December%202021%20-%20Detail.pdf'
vama_report_2022 = 'http://vama.org.vn/Data/upload/files/2022/T12-2022/VAMA%20sales%20report%20December%202022%20-%20Detail.pdf'

sell_ratio['VAMA'] = vama_data
sell_ratio.info()
#Create a ratio column 
sell_ratio['sell_ratio'] = sell_ratio['num_posts'] / sell_ratio['VAMA'] *100
sell_ratio.to_csv('sell_ratio_chotot.csv', index=False)
```

</details>

<details><summary> Extract post, km group by brand :arrow_down: </summary>

```python
#num_posts, mean_km group by brand
brand = df.groupby(['brand']).agg({'km':['mean', 'count']}) #get 2 aggregate functions, extract a DataFrame
brand = brand.reset_index() #reset index
brand.columns = ['brand', 'mean_km', 'num_posts'] #change multiple column names
brand.to_csv('posts_km_groupby_brand.csv', index= False)
```

![image](https://github.com/Cong-hau/analyze-old-car-selling-posts/blob/cffa3cafe1c523a2793272343fdb351b1f437c6b/images/post_brand.png)

</details>

<details><summary> Extract post, km group by brand, carmodel :arrow_down: </summary>

```python
#num_posts, mean_km group by carmodel
carmodel = df.groupby(['brand', 'carmodel'])['km'].agg(['mean', 'size'])
carmodel = carmodel.reset_index()
carmodel.columns = ['brand', 'carmodel', 'mean_km', 'num_posts']
carmodel.to_csv('posts_km_groupby_carmodel.csv', index= False)
```

![image](https://github.com/Cong-hau/analyze-old-car-selling-posts/blob/cffa3cafe1c523a2793272343fdb351b1f437c6b/images/post_carmodel.png)

</details>

<details><summary> Extract post group by city :arrow_down: </summary>

```python
#num_posts group by city
city = df.groupby('city').size()
city = city.reset_index()
city.columns = ['city', 'num_posts']
city.to_csv('posts_groupby_city.csv', index= False)
```

![image](https://github.com/Cong-hau/analyze-old-car-selling-posts/blob/cffa3cafe1c523a2793272343fdb351b1f437c6b/images/post_city.png)

</details>


<details><summary> Extract post group by district in Ho Chi Minh :arrow_down: </summary>

```python
#num_posts group by disctrict in HCM
hcm = df.groupby('city').get_group('Tp Há»“ ChÃ­ Minh')
dis_hcm = hcm.groupby('district').size()
dis_hcm = dis_hcm.reset_index()
dis_hcm.columns = ['district', 'num_posts']
dis_hcm['city'] = 'Há»“ ChÃ­ Minh' #add city column to get hcm's geographic data which used in tableau
dis_hcm.to_csv('posts_groupby_district_hcm.csv', index= False)
```

![image](https://github.com/Cong-hau/analyze-old-car-selling-posts/blob/cffa3cafe1c523a2793272343fdb351b1f437c6b/images/post_dist_hcm.png)

</details>

# Visualize data & Get Insights

<details><summary> Post volumn by brand chart :arrow_down: </summary>

![image](https://github.com/Cong-hau/analyze-old-car-selling-posts/blob/1c9649ee937a2e03d87662cbbe8d31488342f2bc/images/brand's%20post.png)

[Brand's post Dashboard](https://public.tableau.com/app/profile/l.h.u5510/viz/Book1_16759639143440/Dashboard3)

</details>

<details><summary> Post volumn by brand, car model chart :arrow_down: </summary>

![image](https://github.com/Cong-hau/analyze-old-car-selling-posts/blob/1c9649ee937a2e03d87662cbbe8d31488342f2bc/images/carmodel's%20post.png)

[Car Model's post Dashboard](https://public.tableau.com/app/profile/l.h.u5510/viz/Book1_16759639143440/Dashboard4)

</details>

<details><summary> Post volumn by city, district chart :arrow_down: </summary>

![image](https://github.com/Cong-hau/analyze-old-car-selling-posts/blob/1c9649ee937a2e03d87662cbbe8d31488342f2bc/images/city's%20post.png)

[City, district Dashboard](https://public.tableau.com/app/profile/l.h.u5510/viz/Book1_16759639143440/Dashboard2)

</details>

<details><summary> Sell ratio chart :arrow_down: </summary>

![image](https://github.com/Cong-hau/analyze-old-car-selling-posts/blob/1c9649ee937a2e03d87662cbbe8d31488342f2bc/images/sell%20ratio%202.png)

[Sell Ratio Dashboard](https://public.tableau.com/app/profile/l.h.u5510/viz/Book1_16759639143440/Dashboard5)

</details>



